{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sce2rng\\AppData\\Local\\Temp\\ipykernel_22184\\1492364970.py:5: DtypeWarning: Columns (0,2,66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(pathData, sep=\";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494954\n",
      "494953\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pathData = r\"C:\\data\\udacity\\airbnb_global\\airbnb-listings.csv\"\n",
    "\n",
    "data = pd.read_csv(pathData, sep=\";\")\n",
    "\n",
    "# drop raw from data where Country is 0\n",
    "print(len(data))\n",
    "data = data[data['Country'] != '0']\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_df(df, cat_cols, dummy_na = False):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    #\n",
    "    no_categoricals = df.loc[:, ~df.columns.isin(cat_cols)] # der Tilde-Operator ~ verwendet wird, um die Bedingung umzukehren\n",
    "    df_with_cat_cols = df.drop(df.columns[~df.columns.isin(cat_cols)], axis=1)\n",
    "    columns = df_with_cat_cols.columns # get the columns in the right order\n",
    "    \n",
    "    \n",
    "     # 1. + 2. + 3. + 4. + 5.\n",
    "    new_df = pd.get_dummies(df, dummy_na=dummy_na, prefix=columns, drop_first=True) \n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486995\n",
      "Price                   float64\n",
      "Country                  object\n",
      "Latitude                float64\n",
      "Longitude               float64\n",
      "Review Scores Rating    float64\n",
      "Number of Reviews       float64\n",
      "Transit                  object\n",
      "Host Location            object\n",
      "Property Type            object\n",
      "Room Type                object\n",
      "Square Feet             float64\n",
      "Guests Included         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataSel = data[['Price', 'Country', 'Latitude', 'Longitude', 'Review Scores Rating', 'Number of Reviews', 'Transit', 'Host Location', 'Property Type', 'Room Type', 'Square Feet', 'Guests Included']]\n",
    "dataSel = dataSel.dropna(axis=0, subset=[\"Price\"])  # Drop the rows with missing salaries\n",
    "print(len(dataSel))\n",
    "print(dataSel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Price', 'Country', 'Latitude', 'Longitude', 'Review Scores Rating',\n",
      "       'Number of Reviews', 'Host Location', 'Property Type', 'Room Type',\n",
      "       'Square Feet', 'Guests Included', 'TransitBool'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# switch Transit column to boolean column nan values are 0 and other values are 1\n",
    "# assumption everything with no nan have a transit\n",
    "TransitBool = ~data['Transit'].isna()\n",
    "dataSel[\"TransitBool\"]= TransitBool.astype(int)\n",
    "dataSel = dataSel.drop(columns=[\"Transit\"])\n",
    "print(dataSel.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'Host Location', 'Property Type', 'Room Type'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catColumns = dataSel.select_dtypes(include=['object'])\n",
    "catNames = catColumns.columns\n",
    "catNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.44 GiB for an array with shape (12002, 486995) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dummySet \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dummy_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataSel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatNames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dummySet\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[0;32m      3\u001b[0m display(dummySet\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[1;32mIn[14], line 23\u001b[0m, in \u001b[0;36mcreate_dummy_df\u001b[1;34m(df, cat_cols, dummy_na)\u001b[0m\n\u001b[0;32m     19\u001b[0m columns \u001b[38;5;241m=\u001b[39m df_with_cat_cols\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;66;03m# get the columns in the right order\u001b[39;00m\n\u001b[0;32m     22\u001b[0m  \u001b[38;5;66;03m# 1. + 2. + 3. + 4. + 5.\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n",
      "File \u001b[1;32mc:\\Users\\sce2rng\\.conda\\envs\\udacity\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:977\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    973\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (col, pre, sep) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[1;32m--> 977\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[0;32m    987\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sce2rng\\.conda\\envs\\udacity\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:1096\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m concat(sparse_series, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# take on axis=1 + transpose to ensure ndarray layout is column-major\u001b[39;00m\n\u001b[1;32m-> 1096\u001b[0m     dummy_mat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m         dummy_mat[codes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.44 GiB for an array with shape (12002, 486995) and data type uint8"
     ]
    }
   ],
   "source": [
    "dummySet = create_dummy_df(dataSel, catNames)\n",
    "print(len(dummySet.columns))\n",
    "display(dummySet.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mean = lambda col: col.fillna(col.mean()) # calculate the mean of the column and fill the missing values\n",
    "fill_mode = lambda col: col.fillna(col.mode())  # get the most common value of the column and fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dropna[['CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]\n",
    "y = df_dropna['Salary']\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42) \n",
    "\n",
    "lm_model = LinearRegression(normalize=True) # Instantiate\n",
    "lm_model.fit(X_train, y_train) #Fit\n",
    "        \n",
    "#Predict and score the model\n",
    "y_test_preds = lm_model.predict(X_test) \n",
    "\"The r-squared score for your model was {} on {} values.\".format(r2_score(y_test, y_test_preds), len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
